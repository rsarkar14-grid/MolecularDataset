{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOG POST DATA ANALYSIS NOTEBOOK\n",
    "## BY RISHAV SARKAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Many functions used in this notebook are either repetitively called or require to be called externally for multiprocessing\n",
    "> Therefore, almost all of the functions used to process data have been moved to Functions.py\n",
    "> Proper documentation for each function is present there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Lipinski functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 723155.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating Functional group functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 1074922.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing all the required functions and data\n",
    "from Functions import read_sdf\n",
    "from Functions import createButinaClusters\n",
    "from Functions import printClusterImages\n",
    "from Functions import createSubGraphsList\n",
    "from Functions import createGraph\n",
    "from Functions import addMolToSubsetsDict\n",
    "from Functions import createPairsSubsetDict\n",
    "from Functions import addTanimotoSim\n",
    "from Functions import plotCSN\n",
    "from Functions import generateSubGraphImages\n",
    "from Functions import tc_mcs\n",
    "from Functions import lipinski_functions\n",
    "from Functions import functional_groups\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloaded the structures.sdf using the following code in bash\n",
    "\n",
    "```bashcript\n",
    "curl -Lfv -o filename.zip -u btech10404.21@bitmesra.ac.in:PASSWORD https://go.drugbank.com/releases/5-1-13/downloads/all-3d-structures\n",
    "```\n",
    "\n",
    "> Uses student email of institution in order to get access to the DrugBank database for academic research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Molecules list from Molecule supplier object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2648/2648 [00:00<00:00, 9431.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating primary DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2647/2647 [00:01<00:00, 1972.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Removing salts from data...\n",
      "\n",
      "\n",
      "Computing Functional groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:15<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Computing Lipinski properties...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating Molecules list from Molecule supplier object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117229/117229 [00:15<00:00, 7760.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating primary DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117223/117223 [02:29<00:00, 784.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Removing salts from data...\n",
      "\n",
      "\n",
      "Computing Functional groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:47<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Computing Lipinski properties...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the sdf structures and converting them into DataFrames\n",
    "# Also adds columns containing fragments, lipinski, exact_mol_wt, lipophilicity, molecular refractivity\n",
    "# Removes disconnected salts smiles from data for better data processing\n",
    "\n",
    "drug_structures = read_sdf(\"datasets/structures.sdf\", fragments_bool=True, lipinski_bool=True, exact_mol_wt=True, lipophilicity=True, mol_mr=True)\n",
    "toxic_chemicals = read_sdf(\"datasets/toxic_chemicals.sdf\", fragments_bool=True, lipinski_bool=True, exact_mol_wt=True, lipophilicity=True, mol_mr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drug molecules: 2402\n",
      "Number of toxic molecules: 78957\n"
     ]
    }
   ],
   "source": [
    "drug_len = len(drug_structures)\n",
    "toxin_len = len(toxic_chemicals)\n",
    "\n",
    "print(f\"Number of drug molecules: {drug_len}\")\n",
    "print(f\"Number of toxic molecules: {toxin_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ChEMBL ID for each SMILES value in DataFrames\n",
    "> Uses local chembl_35 database and mysqlx library\n",
    "> Uses multithreading to speed up the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching ChEMBL IDs:   0%|          | 0/2402 [00:00<?, ?it/s]/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 819200.00it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 1341125.42it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1733183.47it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3100137.74it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1733183.47it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2991741.31it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1777247.46it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3192679.16it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1426634.01it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2814598.74it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1466539.86it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3077834.59it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1318963.52it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 761243.79it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1777247.46it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2991741.31it/s]\n",
      "Fetching ChEMBL IDs:   0%|          | 1/2402 [00:03<2:17:34,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1613193.85it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2991741.31it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1613193.85it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2430789.82it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1941807.41it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2076791.30it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1997287.62it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3192679.16it/s]\n",
      "Fetching ChEMBL IDs: 100%|██████████| 2402/2402 [02:40<00:00, 14.93it/s]\n",
      "Fetching ChEMBL IDs:   0%|          | 0/78957 [00:00<?, ?it/s]/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rsarkar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "Creating Lipinski functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1855886.73it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3192679.16it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1792437.61it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3290915.45it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1792437.61it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 1074922.13it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1613193.85it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2760122.63it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1792437.61it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3192679.16it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1519675.36it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 1038395.65it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1565038.81it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3012809.92it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n",
      "Creating Lipinski functions list...\n",
      "\n",
      "\n",
      "Creating Functional group functions list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1733183.47it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2991741.31it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1923992.66it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3100137.74it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1718977.05it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2910333.39it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1941807.41it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3122766.48it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1255779.64it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2890668.97it/s]\n",
      "Fetching ChEMBL IDs: 100%|██████████| 78957/78957 [1:26:15<00:00, 15.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from Functions import add_chembl_ids_to_dataframe\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    drug_structures = add_chembl_ids_to_dataframe(drug_structures)\n",
    "    toxic_chemicals = add_chembl_ids_to_dataframe(toxic_chemicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(drug_structures))\n",
    "print(len(toxic_chemicals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_structures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_chemicals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_structures = drug_structures.sample(n=2000)\n",
    "toxic_chemicals = toxic_chemicals.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drug_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(toxic_chemicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_structures = drug_structures.loc[:, ~drug_structures.columns.str.contains('^Unnamed')]\n",
    "toxic_chemicals = toxic_chemicals.loc[:, ~toxic_chemicals.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_structures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipinski_functions.extend(['CHEMBL', 'molecule_type'])\n",
    "drugs_fragments = drug_structures.drop(columns=lipinski_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_fragments = toxic_chemicals.drop(columns=lipinski_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_fragments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_fragments = drug_structures.drop(columns=lipinski_functions+['smiles'])\n",
    "drugs_fragments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_fragments = drugs_fragments.sum().sort_values(ascending=False)\n",
    "toxic_fragments = toxic_fragments.drop(columns='smiles')\n",
    "toxic_fragments = toxic_fragments.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_fragments = pd.concat([drugs_fragments, toxic_fragments], axis=1)\n",
    "concatenated_fragments.columns = ['drugs', 'toxins']\n",
    "\n",
    "concatenated_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_fragments_normalised = concatenated_fragments.apply(lambda x: x*100/len(drug_structures))\n",
    "\n",
    "concatenated_fragments_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_fragments['drugs_normalised'] = concatenated_fragments_normalised['drugs']\n",
    "concatenated_fragments['toxins_normalised'] = concatenated_fragments_normalised['toxins']\n",
    "\n",
    "concatenated_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_fragments = concatenated_fragments.drop(columns=['drugs', 'toxins'])\n",
    "\n",
    "concatenated_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Slider, HoverTool, FactorRange, Toggle\n",
    "from bokeh.transform import dodge\n",
    "\n",
    "def create_functional_groups_plot(df):\n",
    "    \"\"\"\n",
    "    Create an interactive side-by-side bar plot from a DataFrame with 'drugs' and 'toxins' columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with 'drugs' and 'toxins' columns and functional groups as index\n",
    "    \"\"\"\n",
    "    # Sort by drugs count in descending order\n",
    "    df_sorted = df.sort_values('drugs_normalised', ascending=False)\n",
    "    \n",
    "    # Create ColumnDataSource\n",
    "    source = ColumnDataSource(data={\n",
    "        'functional_groups': df_sorted.index.tolist(),\n",
    "        'drugs_normalised': df_sorted['drugs_normalised'].values,\n",
    "        'toxins_normalised': df_sorted['toxins_normalised'].values\n",
    "    })\n",
    "    \n",
    "    # Create original source for the slider\n",
    "    original_source = ColumnDataSource(source.data)\n",
    "    \n",
    "    # Create figure with proper x_range\n",
    "    x_range = FactorRange(factors=df_sorted.index.tolist(), range_padding=0.1)\n",
    "    p = figure(x_range=x_range,\n",
    "              height=500, \n",
    "              width=900,\n",
    "              title='Functional Groups Distribution in Drugs vs Toxins',\n",
    "              toolbar_location='right')\n",
    "    \n",
    "    # Create side-by-side bars with minimal spacing\n",
    "    dodge_amount = 0.1  # Reduced dodge amount\n",
    "    drugs_bars = p.vbar(x=dodge('functional_groups', -dodge_amount, range=p.x_range),\n",
    "                       top='drugs_normalised',\n",
    "                       width=0.15,  # Reduced width\n",
    "                       source=source,\n",
    "                       color='#2196F3',\n",
    "                       legend_label='Drugs')\n",
    "    \n",
    "    toxins_bars = p.vbar(x=dodge('functional_groups', dodge_amount, range=p.x_range),\n",
    "                        top='toxins_normalised',\n",
    "                        width=0.15,  # Reduced width\n",
    "                        source=source,\n",
    "                        color='#FF5722',\n",
    "                        legend_label='Toxins')\n",
    "    \n",
    "    # Customize the plot\n",
    "    p.xaxis.axis_label = 'Functional Groups'\n",
    "    p.yaxis.axis_label = 'Percentage of molecules'\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis.major_label_orientation = 45\n",
    "    p.legend.click_policy = 'hide'\n",
    "    p.legend.location = 'top_right'\n",
    "    \n",
    "    # Add hover tool\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [\n",
    "        ('Functional Group', '@functional_groups'),\n",
    "        ('Drugs Count', '@drugs_normalised %'),\n",
    "        ('Toxins Count', '@toxins_normalised %')\n",
    "    ]\n",
    "    hover.renderers = [drugs_bars, toxins_bars]\n",
    "    p.add_tools(hover)\n",
    "    \n",
    "    # Create slider\n",
    "    slider = Slider(start=1,\n",
    "                   end=len(df),\n",
    "                   value=len(df),\n",
    "                   step=1,\n",
    "                   title='Number of Top Functional Groups')\n",
    "    \n",
    "    # Create callback for slider\n",
    "    slider_callback = CustomJS(args=dict(source=source,\n",
    "                                original=original_source,\n",
    "                                slider=slider,\n",
    "                                p=p), code=\"\"\"\n",
    "        // Get the current slider value\n",
    "        const n = slider.value;\n",
    "        \n",
    "        // Get the data\n",
    "        const data = source.data;\n",
    "        const original_data = original.data;\n",
    "        \n",
    "        // Update the data with top n values\n",
    "        data['functional_groups'] = original_data['functional_groups'].slice(0, n);\n",
    "        data['drugs_normalised'] = original_data['drugs_normalised'].slice(0, n);\n",
    "        data['toxins_normalised'] = original_data['toxins_normalised'].slice(0, n);\n",
    "\n",
    "        \n",
    "        // Update x-range\n",
    "        p.x_range.factors = data['functional_groups'];\n",
    "        \n",
    "        // Trigger update\n",
    "        source.change.emit();\n",
    "    \"\"\")\n",
    "    \n",
    "    # Connect callback to slider\n",
    "    slider.js_on_change('value', slider_callback)\n",
    "    # Create layout\n",
    "    layout = column(slider, p)\n",
    "    \n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show the plot\n",
    "plot = create_functional_groups_plot(concatenated_fragments)\n",
    "output_file(filename=\"Functional_Groups_Plot.html\", title=\"Functional Groups Plot\")\n",
    "show(plot)\n",
    "# show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import plot_rules\n",
    "\n",
    "drugs_rules = plot_rules(drug_structures)\n",
    "toxins_rules = plot_rules(toxic_chemicals)\n",
    "\n",
    "drugs_rules_normalised = plot_rules(drug_structures, normalise=True)\n",
    "toxins_rules_normalised = plot_rules(toxic_chemicals, normalise=True)\n",
    "\n",
    "print(toxins_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toxins_rules_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules = pd.concat([drugs_rules, toxins_rules], axis=1)\n",
    "screening_rules.columns = ['drugs', 'toxins']\n",
    "\n",
    "screening_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules_normalised = pd.concat([drugs_rules_normalised, toxins_rules_normalised], axis=1)\n",
    "screening_rules_normalised.columns = ['drugs', 'toxins']\n",
    "\n",
    "screening_rules_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules['drugs_normalised'] = screening_rules_normalised['drugs']\n",
    "screening_rules['toxins_normalised'] = screening_rules_normalised['toxins']\n",
    "\n",
    "screening_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules = screening_rules.drop(columns=['drugs', 'toxins'])\n",
    "\n",
    "screening_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [\"Lipinski's rule of five is a computational procedure that predicts whether a chemical compound is likely to be orally active in humans. It's used in drug discovery to estimate a compound's solubility, membrane permeability, and pharmacological effectiveness.\",\n",
    "        \"The Ghose filter is a knowledge-based filter that helps identify drug-like chemical spaces. It can be used to design libraries for medicinal chemistry and combinatorial chemistry. \",\n",
    "        \"Veber's rule is a set of guidelines that help predict how well a drug will be absorbed orally. It's based on a molecule's structure, and considers the number of rotatable bonds and its polar surface area. \",\n",
    "        \"The Egan rule is a set of guidelines that help predict how well a small molecule will be absorbed orally. It's based on a computational model called the Egan filter, which uses multivariate statistics to analyze data from well- and poorly-absorbed compounds. \",\n",
    "        \"The REOS filter is a filter designed to filter out unuseful compounds from HTS screening results, and is described in Waters & Namchuk, Nature Reviews Drug Discovery 2, 259-266 (2003).\",\n",
    "        \"A drug-like filter is a tool that helps identify compounds with properties that make them more likely to be effective drugs. These filters are used in medicinal chemistry to help select compounds for further testing. \",\n",
    "        \"Fails all the mentioned drug screening tests\",\n",
    "        \"The rule of three in drug discovery is a set of guidelines for the physicochemical properties of molecules. It's also used in clinical trials to estimate the likelihood of rare adverse events. \",\n",
    "        \"Passes all the mentioned drug screening tests\"]\n",
    "\n",
    "screening_rules['info'] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool, TapTool, CustomJS, Div\n",
    "from bokeh.layouts import column\n",
    "from bokeh.transform import dodge\n",
    "import pandas as pd\n",
    "\n",
    "def interactive_bokeh_bar_plot(df: pd.DataFrame):\n",
    "    df_sorted = df.sort_values(by='drugs_normalised', ascending=False)\n",
    "    categories = df_sorted.index.tolist()\n",
    "    \n",
    "    data_source = ColumnDataSource(data={\n",
    "        'index': categories,\n",
    "        'drugs': df_sorted['drugs_normalised'].tolist(),\n",
    "        'toxins': df_sorted['toxins_normalised'].tolist(),\n",
    "        'info': df_sorted['info'].tolist()\n",
    "    })\n",
    "    \n",
    "    p = figure(x_range=categories, title='Drugs vs Toxins', x_axis_label='Categories', y_axis_label='Values', tools=\"pan,wheel_zoom,box_zoom,reset,tap\")\n",
    "    p.vbar(x=dodge('index', -0.15, range=p.x_range), top='drugs', source=data_source, width=0.3, color='blue', legend_label='Drugs')\n",
    "    p.vbar(x=dodge('index', 0.15, range=p.x_range), top='toxins', source=data_source, width=0.3, color='red', legend_label='Toxins')\n",
    "    \n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"Category\", \"@index\"),\n",
    "        (\"Drugs\", \"@drugs %\"),\n",
    "        (\"Toxins\", \"@toxins %\")\n",
    "    ])\n",
    "    p.add_tools(hover)\n",
    "    \n",
    "    info_box = Div(text=\"<span style='font-size:16px;'><b>Click a bar to see more info</b></span>\", width=400, height=100)\n",
    "    \n",
    "    tap_callback = CustomJS(args=dict(source=data_source, info_box=info_box), code=\"\"\"\n",
    "        var selected = source.selected.indices;\n",
    "        if (selected.length > 0) {\n",
    "            var index = selected[0];\n",
    "            var info = source.data['info'][index];\n",
    "            info_box.text = \"<span style='font-size:16px;'><b>Info:</b> \" + info + \"</span>\";\n",
    "        }\n",
    "    \"\"\")\n",
    "    \n",
    "    tap_tool = p.select(type=TapTool)\n",
    "    tap_tool.callback = tap_callback\n",
    "    \n",
    "    layout = column(p, info_box)\n",
    "    output_file(filename=\"bar_plot.html\")\n",
    "    # save(layout)\n",
    "    show(layout)\n",
    "\n",
    "# Example Usage:\n",
    "# df = pd.DataFrame({\n",
    "#     'drugs': [100, 200, 150, 180, 90],\n",
    "#     'toxins': [120, 190, 160, 170, 85],\n",
    "#     'info': ['Details about A', 'Details about B', 'Details about C', 'Details about D', 'Details about E']\n",
    "# }, index=['A', 'B', 'C', 'D', 'E'])\n",
    "# interactive_bokeh_bar_plot(df)\n",
    "\n",
    "interactive_bokeh_bar_plot(screening_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_molecules = pd.concat([drug_structures, toxic_chemicals]).sample(frac=1)\n",
    "\n",
    "concatenated_molecules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = createButinaClusters(concatenated_molecules)\n",
    "printClusterImages(clusters, directory_name='labeled_clusters', file_names='cluster', subImgSize=(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Functions import createMolsNodesData\n",
    "\n",
    "drug_structures_sample = drug_structures.sample(n=500)\n",
    "toxic_chemicals_sample = toxic_chemicals.sample(n=500)\n",
    "\n",
    "concatenated_molecules = concatenated_molecules.drop_duplicates(subset='smiles').sample(frac=1)\n",
    "\n",
    "# nodes_data = createMolsNodesData(concatenated_molecules, smiles_column='smiles', value_column='molecule_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsets_dict = createPairsSubsetDict(nodes_data)\n",
    "# addMolToSubsetsDict(subsets_dict)\n",
    "# addTanimotoSim(subsets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Creating tuples from subsets dictionary...\")\n",
    "# mols_tuples = []\n",
    "# for key, value in tqdm(subsets_dict.items()):\n",
    "#     mols_tuples.append((value['mol1'], value['mol2'], key))\n",
    "# print(\"\\n\")\n",
    "\n",
    "# num_cpus = cpu_count()-2\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     with Pool(num_cpus) as p:\n",
    "#         star_map = p.starmap(tc_mcs, mols_tuples)\n",
    "#     for key, tan_mcs in star_map:\n",
    "#         subsets_dict[key].update({\"tan_mcs\": round(tan_mcs, 3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = createGraph(subsets=subsets_dict, node_data=nodes_data, attrib_name='molecule_type', useMCS=True, filter_thresh=0.8)\n",
    "\n",
    "# # Creating color map list for coloring nodes\n",
    "# color_map = []\n",
    "# for node in graph.nodes(data=True):\n",
    "#     if node[1]['attrib'] == 'drug':\n",
    "#         color_map.append('red')\n",
    "#     elif node[1]['attrib'] == 'toxin':\n",
    "#         color_map.append('blue')\n",
    "\n",
    "# plotCSN(graph=graph, save_file=True, file_name=\"full_cluster_map_4\", k=0.3,color_map=color_map, edge_colors=\"black\", figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connected_subgraphs = createSubGraphsList(graph)\n",
    "\n",
    "# generateSubGraphImages(connected_subgraphs, k=0.8, scale=2, figsize=(12,12), folder_path='sub-graphs10', min_nodes_thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# for component in list(nx.connected_components(graph)):\n",
    "#     if len(component) < 2:\n",
    "#         for node in component:\n",
    "#             graph.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining color_map for updated graph\n",
    "# color_map = []\n",
    "# for node in graph.nodes(data=True):\n",
    "#     if node[1]['attrib'] == 'drug':\n",
    "#         color_map.append('red')\n",
    "#     elif node[1]['attrib'] == 'toxin':\n",
    "#         color_map.append('blue')\n",
    "\n",
    "# plotCSN(graph=graph, save_file=True, file_name=\"full_cluster_map_filtered\", k=0.3,color_map=color_map, edge_colors=\"black\", figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Functions import structureCSNMap\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "\n",
    "# directory = 'structureCSN'\n",
    "# file_name = 'csn'\n",
    "\n",
    "# os.mkdir(directory)\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Generating only those subgraphs with more than 2 nodes\n",
    "# print(\"Generating chemical structure based CSNs...\")\n",
    "# for i in tqdm(range(len(connected_subgraphs))):\n",
    "#     if len(connected_subgraphs[i]) < 3:\n",
    "#         continue\n",
    "#     file_path = os.path.join(directory, file_name)+f\"{i}\"\n",
    "#     structureCSNMap(connected_subgraphs[i], file_path_name=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(nodes_data.values())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(subsets_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Functions import pickle_data\n",
    "\n",
    "# pickle_data(subsets_dict, file_name='subsets_dict')\n",
    "# pickle_data(nodes_data, file_name='nodes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure, from_networkx\n",
    "from bokeh.models import (HoverTool, ColumnDataSource, ImageURL, GraphRenderer)\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to generate image URLs from Mol objects\n",
    "def mol_to_base64(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    img = Draw.MolToImage(mol, size=(150, 150))\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"PNG\")\n",
    "    encoded = base64.b64encode(buffer.getvalue()).decode()\n",
    "    return f\"data:image/png;base64,{encoded}\"\n",
    "\n",
    "# Example input dictionaries\n",
    "nodes_data = {\n",
    "    \"CCO\": {\"CHEMBL\": \"CHEMBL1\", \"molecule_type\": \"drug\"},\n",
    "    \"CCN\": {\"CHEMBL\": \"CHEMBL2\", \"molecule_type\": \"toxin\"}\n",
    "}\n",
    "\n",
    "subsets_dict = {\n",
    "    1: {\n",
    "        \"smi1\": \"CCO\", \"smi2\": \"CCN\", \"mol1\": None, \"mol2\": None,\n",
    "        \"tan_sim\": 0.8, \"tan_mcs\": 0.6\n",
    "    }\n",
    "}\n",
    "\n",
    "# Creating the graph\n",
    "G = nx.Graph()\n",
    "node_images = {}\n",
    "\n",
    "for key, value in subsets_dict.items():\n",
    "    smi1, smi2 = value[\"smi1\"], value[\"smi2\"]\n",
    "    G.add_node(smi1, image=mol_to_base64(value[\"smi1\"]))\n",
    "    G.add_node(smi2, image=mol_to_base64(value[\"smi2\"]))\n",
    "    G.add_edge(smi1, smi2, tan_sim=value[\"tan_sim\"], tan_mcs=value[\"tan_mcs\"])\n",
    "    node_images[smi1] = mol_to_base64(value[\"smi1\"])\n",
    "    node_images[smi2] = mol_to_base64(value[\"smi2\"])\n",
    "\n",
    "# Generate positions\n",
    "pos = nx.spring_layout(G, scale=1, center=(0, 0))\n",
    "x, y = zip(*pos.values())\n",
    "nodes = list(G.nodes)\n",
    "\n",
    "# Create data source for Bokeh\n",
    "source = ColumnDataSource(\n",
    "    data={\n",
    "        \"x\": [pos[node][0] for node in nodes],\n",
    "        \"y\": [pos[node][1] for node in nodes],\n",
    "        \"image\": [node_images[node] for node in nodes],\n",
    "        \"molecule\": nodes\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create plot\n",
    "plot = figure(title=\"Molecular Network\", x_range=(-1, 1), y_range=(-1, 1), tools=\"pan,wheel_zoom,reset\")\n",
    "network_graph = from_networkx(G, nx.spring_layout, scale=1, center=(0, 0))\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "# Add image glyphs for molecules\n",
    "plot.image_url(url=\"image\", x=\"x\", y=\"y\", w=0.1, h=0.1, source=source, anchor=\"center\")\n",
    "\n",
    "# Add hover tool\n",
    "tooltips = [\n",
    "    (\"Molecule\", \"@molecule\"),\n",
    "    (\"Tanimoto Similarity\", \"@tan_sim\"),\n",
    "    (\"Tanimoto MCS\", \"@tan_mcs\")\n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "plot.add_tools(hover)\n",
    "\n",
    "# Show plot\n",
    "output_file(\"network_graph.html\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "admet_data_drugs = pd.read_csv(\"admet_data_drugs_updated.csv\")\n",
    "admet_data_toxins = pd.read_csv(\"admet_data_toxins_updated.csv\")\n",
    "\n",
    "nested_dict = {\n",
    "    col: pd.DataFrame({'drugs': admet_data_drugs[col], 'toxins': admet_data_toxins[col]}).dropna()\n",
    "    for col in admet_data_drugs.columns if col != 'CHEMBL_ID'\n",
    "}\n",
    "\n",
    "for key, value in nested_dict.items():\n",
    "    n = len(value)\n",
    "    print(f\"Length of {key} = {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict.pop(\"ChEMBL_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nested_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict['Ki'] = nested_dict['Ki'].applymap(lambda x: -1*math.log10(x))\n",
    "\n",
    "print(nested_dict['Ki'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict['Kd'] = nested_dict['Kd'].map(lambda x: -1*math.log10(x))\n",
    "\n",
    "print(nested_dict['Kd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['EC50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['MIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['PPB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['Vd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['Potency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "plt.xlabel(\"Potency\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['Potency']['drugs'], log_scale=True)\n",
    "sns.kdeplot(data=nested_dict['Potency']['toxins'], log_scale=True)\n",
    "plt.xlabel(\"Potency\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['EC50']['drugs'], log_scale=True)\n",
    "sns.kdeplot(data=nested_dict['EC50']['toxins'], log_scale=True)\n",
    "plt.xlabel(\"EC50\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['CL']['drugs'], log_scale=True)\n",
    "sns.kdeplot(data=nested_dict['CL']['toxins'], log_scale=True)\n",
    "plt.xlabel(\"CL\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict['EC50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x in nested_dict['Activity']['drugs']:\n",
    "    if x < 0:\n",
    "        i = i+1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nested_dict['IC50'])\n",
    "\n",
    "i = 0\n",
    "for x in nested_dict['IC50']['toxins']:\n",
    "    if x == 0:\n",
    "        i=i+1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nested_dict['IC50']\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "mask = (df_cleaned != 0).all(axis=1)\n",
    "df = df[mask]\n",
    "nested_dict['IC50'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nested_dict['IC50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['IC50']['drugs'].apply(lambda x: math.log10(x)))\n",
    "sns.kdeplot(data=nested_dict['IC50']['toxins'].apply(lambda x: math.log10(x)))\n",
    "plt.xlabel(\"EC50\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_kde = sns.kdeplot(data=nested_dict['Ki']['drugs'])\n",
    "toxins_kde = sns.kdeplot(data=nested_dict['Ki']['toxins'])\n",
    "x1 = drugs_kde.get_data()['x']\n",
    "y1 = drugs_kde.get_data()['y']\n",
    "x2 = toxins_kde.get_data()['x']\n",
    "y2 = toxins_kde.get_data()['y']\n",
    "plt.xlabel(\"Ki\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['Kd']['drugs'])\n",
    "sns.kdeplot(data=nested_dict['Kd']['toxins'])\n",
    "plt.xlabel(\"Ki\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_structures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Crippen\n",
    "\n",
    "drug_structures['logP'] = drug_structures['smiles'].apply(lambda x: Crippen.MolLogP(Chem.MolFromSmiles(x)))\n",
    "drug_structures['MR'] = drug_structures['smiles'].apply(lambda x: Crippen.MolMR(Chem.MolFromSmiles(x)))\n",
    "\n",
    "toxic_chemicals['logP'] = toxic_chemicals['smiles'].apply(lambda x: Crippen.MolLogP(Chem.MolFromSmiles(x)))\n",
    "toxic_chemicals['MR'] = toxic_chemicals['smiles'].apply(lambda x: Crippen.MolMR(Chem.MolFromSmiles(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=drug_structures['logP'])\n",
    "sns.kdeplot(data=toxic_chemicals['logP'])\n",
    "plt.xlabel(\"logP\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=drug_structures['MR'])\n",
    "sns.kdeplot(data=toxic_chemicals['MR'])\n",
    "plt.xlabel(\"MR\", size=10)\n",
    "# plt.xlim([-0.2, 0.2])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x=drug_structures['MR'], y=drug_structures['logP'])\n",
    "sns.kdeplot(x=toxic_chemicals['MR'], y=toxic_chemicals['logP'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(nested_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict_filtered = {k: v for k, v in nested_dict.items() if len(v) > 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict_filtered.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict_filtered['Solubility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_mr = drug_structures['MR']\n",
    "toxins_mr = toxic_chemicals['MR'][0:len(drug_structures)]\n",
    "\n",
    "nested_dict['MR'] = pd.DataFrame({'drugs': drugs_mr, 'toxins': toxins_mr}).dropna()\n",
    "nested_dict['logP'] = pd.DataFrame({'drugs': drug_structures['logP'], 'toxins': toxic_chemicals['logP']}).dropna()\n",
    "\n",
    "nested_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=nested_dict['LC50']['drugs'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_colors(dataframes_dict):\n",
    "    num_dfs = len(dataframes_dict)  # Number of dataframes\n",
    "    colors = sns.color_palette(\"tab10\", num_dfs * 2)  # Generate enough unique colors\n",
    "    \n",
    "    color_mapping = {}\n",
    "    \n",
    "    for i, df_name in enumerate(dataframes_dict.keys()):\n",
    "        color_mapping[df_name] = {\n",
    "            'drugs': colors[i * 2],\n",
    "            'toxins': colors[i * 2 + 1]\n",
    "        }\n",
    "    \n",
    "    return color_mapping\n",
    "\n",
    "color_mapping = generate_unique_colors(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = 'kde_plots'\n",
    "os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict['t_half'] = nested_dict['T1/2']\n",
    "del nested_dict['T1/2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'kde_plots'\n",
    "os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = generate_unique_colors(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict['Solubility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = ['CL', 'MIC', 'EC50', 'Potency', 't_half', 'Solubility']\n",
    "for key, value in nested_dict.items():\n",
    "    file_name = key+\".png\"\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    drug_color = color_mapping[key]['drugs']\n",
    "    toxin_color = color_mapping[key]['toxins']\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    if key in logs:\n",
    "        sns.kdeplot(data=value['drugs'], fill=True, color=drug_color, log_scale=True, label=\"Drugs\")\n",
    "        sns.kdeplot(data=value['toxins'], fill=True, color=toxin_color, log_scale=True, label=\"Toxins\")\n",
    "    else:\n",
    "        sns.kdeplot(data=value['drugs'], fill=True, color=drug_color, label=\"Drugs\")\n",
    "        sns.kdeplot(data=value['toxins'], fill=True, color=toxin_color, label=\"Toxins\")\n",
    "    ax.legend()\n",
    "    plt.xlabel(key, size=10)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.grid(True, linestyle=\"--\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
